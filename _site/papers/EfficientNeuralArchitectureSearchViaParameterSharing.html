<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Efficient Neural Architecture Search Via Parameter Sharing | saubhik</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Efficient Neural Architecture Search Via Parameter Sharing" />
<meta name="author" content="Saubhik Mukherjee" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Personal cyber-space dump." />
<meta property="og:description" content="Personal cyber-space dump." />
<link rel="canonical" href="http://localhost:4000/papers/EfficientNeuralArchitectureSearchViaParameterSharing.html" />
<meta property="og:url" content="http://localhost:4000/papers/EfficientNeuralArchitectureSearchViaParameterSharing.html" />
<meta property="og:site_name" content="saubhik" />
<script type="application/ld+json">
{"description":"Personal cyber-space dump.","author":{"@type":"Person","name":"Saubhik Mukherjee"},"@type":"WebPage","url":"http://localhost:4000/papers/EfficientNeuralArchitectureSearchViaParameterSharing.html","headline":"Efficient Neural Architecture Search Via Parameter Sharing","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=7f90a6ed2a8ee84cfa7f3ceb5a300c7e86b460f3">
    <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1><a href="http://localhost:4000/">saubhik</a></h1>

        

        <p>Personal cyber-space dump.</p>

        <p class="view"><a href="https://github.com/saubhik/">View my GitHub profile<small>github.com/saubhik</small></a></p>
        <p class="view"><a href="/posts.html">Blog<small>/posts</small></a></p>

        

        <a href="/index.html">Home</a>
</br><a href="/papers/">Comments on deep learning papers</a>
</br><a href="/epi/">Elements Of Programming Interviews</a>
</br><a href="/software_development/">Software Development</a>
</br><a href="/utilities/">Utilities</a>
</br><a href="/data_science/">Data Science</a>
</br><a href="/notebooks/">Jupyter Notebooks</a>
</br><a href="/deep_learning/">Deep Learning</a>
</br><a href="/coursework/index.html">CS courses notes</a>
</br><a href="/this_site/">About this website</a>
</br><a href="/practice-javascript/">Practice Javascript</a>


      </header>
      <section>

      <h1 id="efficient-neural-architecture-search-via-parameter-sharing">Efficient Neural Architecture Search Via Parameter Sharing</h1>

<h2 id="methods">Methods</h2>
<p>All of the graphs which NAS ends up iterating over can be viewed as sub-graphs
of a larger graph. We can represent NAS’s search space using a single directed
acyclic graph (DAG). Nodes represent local computation and the edges represent
the flow of information. The local computations at each node have their own
parameters, which are used only when the particular computation is activated.
Therefore, ENAS’s design allows parameters to be shared among all child models.
i.e. architectures, in the search space.</p>

<p>Topics:</p>
<ul>
  <li>how to design a cell for RNN from a specified DAG and a controller</li>
  <li>how to train ENAS and how to derive architectures from ENAS’s controller</li>
  <li>explain search space for designing convolutional architectures</li>
</ul>

<h3 id="designing-recurrent-cells">Designing Recurrent Cells</h3>
<p>ENAS’s controller is an RNN that decides:</p>
<ul>
  <li>which edges are activated</li>
  <li>which computations are performed at each node in the DAG</li>
</ul>

<p>To create a recurrent cell, the controller RNN samples <script type="math/tex">N</script> blocks of
decisions.</p>

<p>An example illustation via a simple example recurrent cell with <script type="math/tex">N=4</script>
computational nodes:
Let \( x_t \) be the input signal for a recurrent cell, and \(h_{t-1}\) be the
output from the previous time step.</p>

<ol>
  <li>
    <p>The controller first samples an activation function. If controller chooses
  \(tanh\) activation function, which means node \(1\) of the recurrent
  cell should compute \(h_1=tanh(x_t \cdot W^{x} + h_{t-1} \cdot W_{1}^{h})\).</p>
  </li>
  <li>
    <p>At other nodes, the controller samples a previous index (say \( j \) ), and
  an activation function, (say \( ReLU \) ). We have \( h_i = ReLU(h_j \cdot
  W^{h}_{i,j}) \).</p>
  </li>
  <li>
    <p>For output, we average the nodes that are not selected as previous index.</p>
  </li>
</ol>

<p>For each pair \( (i,j) \) of nodes, there is an independent parameter matrix
\( W^{h}_{i,j} \) which are shared by all recurrent cells in ENAS.</p>

<p>If the recurrent cell has \( N \) nodes, and we allow \( 4 \) activation
functions (like <code class="highlighter-rouge">tanh</code>, <code class="highlighter-rouge">ReLU</code>, <code class="highlighter-rouge">identity</code>, <code class="highlighter-rouge">sigmoid</code>), then the search space
has \( 4^N \times N! \) configurations, i.e. architectures.</p>

<p>The paper uses \( N = 12 \).</p>

<h3 id="training-enas-and-deriving-architectures">Training ENAS and Deriving Architectures</h3>


      </section>
      <footer>
        <p><small>Love &mdash; Peace &mdash; Code</small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>